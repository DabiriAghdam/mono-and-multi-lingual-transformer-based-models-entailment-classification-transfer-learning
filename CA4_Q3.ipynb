{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWEJn-xxMzxS"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DXqkWkPANwOe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "import random\n",
        "import regex as re\n",
        "import logging\n",
        "from tqdm import tqdm, trange\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import XLMRobertaTokenizer\n",
        "from transformers.models.xlm_roberta.modeling_xlm_roberta import  XLMRobertaModel, XLMRobertaConfig\n",
        "from transformers import BertConfig, BertTokenizer, BertModel\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NDvbMSvmO9Mp",
        "outputId": "a669f8a4-6c41-44db-e097-19a9df9eed02"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e10ce5a9-d099-4059-925a-e5118a6e8462\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>targets</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When news is brought to one of them, of (the b...</td>\n",
              "      <td>و چون یکی از آنان را به [ولادت] دختر مژده دهند...</td>\n",
              "      <td>quran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>After them repaired Zadok the son of Immer ove...</td>\n",
              "      <td>و چون دشمنان ما شنیدند که ما آگاه شده‌ایم و خد...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>And establish regular prayers at the two ends ...</td>\n",
              "      <td>و نماز را در دو طرف روز و ساعات نخستین شب برپا...</td>\n",
              "      <td>quran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>And it came to pass, that, when I was come aga...</td>\n",
              "      <td>و فرمود تا مدعیانش نزد تو حاضر شوند؛ و از او ب...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ah woe, that Day, to the Rejecters of Truth!</td>\n",
              "      <td>وای در آن روز بر تکذیب کنندگان!</td>\n",
              "      <td>quran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12595</th>\n",
              "      <td>Women impure are for men impure, and men impur...</td>\n",
              "      <td>زنان پلید برای مردان پلید و مردان پلید برای زن...</td>\n",
              "      <td>quran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12596</th>\n",
              "      <td>I don't want any silly dance given in my honour.'</td>\n",
              "      <td>بنابراین حالا هم میل ندارم جشنی به افتخار من د...</td>\n",
              "      <td>mizan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12597</th>\n",
              "      <td>And the Earth will shine with the Glory of its...</td>\n",
              "      <td>و زمین به نور پروردگارش روشن می‌شود، و کتاب [ا...</td>\n",
              "      <td>quran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12598</th>\n",
              "      <td>Then lifted I up mine eyes, and saw, and behol...</td>\n",
              "      <td>گفتم: «این چیست؟» او جواب داد: «این است آن ایف...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12599</th>\n",
              "      <td>His soul was dried up.</td>\n",
              "      <td>روح خشکیده بود.</td>\n",
              "      <td>mizan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12600 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e10ce5a9-d099-4059-925a-e5118a6e8462')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e10ce5a9-d099-4059-925a-e5118a6e8462 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e10ce5a9-d099-4059-925a-e5118a6e8462');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  source  \\\n",
              "0      When news is brought to one of them, of (the b...   \n",
              "1      After them repaired Zadok the son of Immer ove...   \n",
              "2      And establish regular prayers at the two ends ...   \n",
              "3      And it came to pass, that, when I was come aga...   \n",
              "4           Ah woe, that Day, to the Rejecters of Truth!   \n",
              "...                                                  ...   \n",
              "12595  Women impure are for men impure, and men impur...   \n",
              "12596  I don't want any silly dance given in my honour.'   \n",
              "12597  And the Earth will shine with the Glory of its...   \n",
              "12598  Then lifted I up mine eyes, and saw, and behol...   \n",
              "12599                             His soul was dried up.   \n",
              "\n",
              "                                                 targets category  \n",
              "0      و چون یکی از آنان را به [ولادت] دختر مژده دهند...    quran  \n",
              "1      و چون دشمنان ما شنیدند که ما آگاه شده‌ایم و خد...    bible  \n",
              "2      و نماز را در دو طرف روز و ساعات نخستین شب برپا...    quran  \n",
              "3      و فرمود تا مدعیانش نزد تو حاضر شوند؛ و از او ب...    bible  \n",
              "4                        وای در آن روز بر تکذیب کنندگان!    quran  \n",
              "...                                                  ...      ...  \n",
              "12595  زنان پلید برای مردان پلید و مردان پلید برای زن...    quran  \n",
              "12596  بنابراین حالا هم میل ندارم جشنی به افتخار من د...    mizan  \n",
              "12597  و زمین به نور پروردگارش روشن می‌شود، و کتاب [ا...    quran  \n",
              "12598  گفتم: «این چیست؟» او جواب داد: «این است آن ایف...    bible  \n",
              "12599                                    روح خشکیده بود.    mizan  \n",
              "\n",
              "[12600 rows x 3 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train = pd.read_excel('train.xlsx')\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "dQ_gfj_sP97r",
        "outputId": "9274631d-caff-49ec-8688-9df823b25611"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bible': 0.3333333333333333,\n",
              " 'mizan': 0.3333333333333333,\n",
              " 'quran': 0.33325396825396825}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "freq_dict = dict()\n",
        "for i in range(1, len(df_train)):\n",
        "    data = df_train.iloc[i]\n",
        "    if (data['category'] in freq_dict): freq_dict[data['category']] += 1\n",
        "    else: freq_dict[data['category']] = 1\n",
        "\n",
        "for k,v in freq_dict.items():\n",
        "    freq_dict[k] = v / len(df_train)\n",
        "\n",
        "sns.countplot(x=df_train['category'])\n",
        "freq_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kArG569cPL4g",
        "outputId": "febd17df-5d95-482a-8cf6-d857e33e6575"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2f0e8d06-2989-4081-8a6e-71075da17121\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>targets</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>And there came out a fire from the LORD, and c...</td>\n",
              "      <td>تا برای بنی‌اسرائیل یادگارباشد تا هیچ غریبی که...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>And out of them shall proceed thanksgiving and...</td>\n",
              "      <td>ویهودا و تمامی شهرهایش با هم و فلاحان و آنانی ...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>So We sent against them a furious Wind through...</td>\n",
              "      <td>سرانجام تندبادی سخت و سرد در روزهایی شوم بر آن...</td>\n",
              "      <td>quran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"And drink Boiling Water on top of it:</td>\n",
              "      <td>و روی آن از آب جوشان خواهید نوشید،</td>\n",
              "      <td>quran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I was starting to get sleepythough, according ...</td>\n",
              "      <td>داشت خوابم می‌گرفت اگرچه، به گفته‌ی ادوارد نصف...</td>\n",
              "      <td>mizan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2695</th>\n",
              "      <td>And he left the oxen, and ran after Elijah, an...</td>\n",
              "      <td>و اینک نبی‌ای نزد اخاب، پادشاه اسرائیل آمده، گ...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2696</th>\n",
              "      <td>Then which of the favours of your Lord will ye...</td>\n",
              "      <td>پس کدامیک از نعمت‌های پروردگارتان را انکار می‌...</td>\n",
              "      <td>quran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2697</th>\n",
              "      <td>That was the deal, the price.</td>\n",
              "      <td>آن قرار و عهد ما بود. بهای آن.</td>\n",
              "      <td>mizan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2698</th>\n",
              "      <td>And when we burned incense to the queen of hea...</td>\n",
              "      <td>کلامی که خداوند درباره آمدن نبوکدرصرپادشاه باب...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2699</th>\n",
              "      <td>And Joseph answered and said, This is the inte...</td>\n",
              "      <td>پس در روز سوم که یوم میلاد فرعون بود، ضیافتی ب...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2700 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f0e8d06-2989-4081-8a6e-71075da17121')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f0e8d06-2989-4081-8a6e-71075da17121 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f0e8d06-2989-4081-8a6e-71075da17121');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 source  \\\n",
              "0     And there came out a fire from the LORD, and c...   \n",
              "1     And out of them shall proceed thanksgiving and...   \n",
              "2     So We sent against them a furious Wind through...   \n",
              "3                \"And drink Boiling Water on top of it:   \n",
              "4     I was starting to get sleepythough, according ...   \n",
              "...                                                 ...   \n",
              "2695  And he left the oxen, and ran after Elijah, an...   \n",
              "2696  Then which of the favours of your Lord will ye...   \n",
              "2697                      That was the deal, the price.   \n",
              "2698  And when we burned incense to the queen of hea...   \n",
              "2699  And Joseph answered and said, This is the inte...   \n",
              "\n",
              "                                                targets category  \n",
              "0     تا برای بنی‌اسرائیل یادگارباشد تا هیچ غریبی که...    bible  \n",
              "1     ویهودا و تمامی شهرهایش با هم و فلاحان و آنانی ...    bible  \n",
              "2     سرانجام تندبادی سخت و سرد در روزهایی شوم بر آن...    quran  \n",
              "3                    و روی آن از آب جوشان خواهید نوشید،    quran  \n",
              "4     داشت خوابم می‌گرفت اگرچه، به گفته‌ی ادوارد نصف...    mizan  \n",
              "...                                                 ...      ...  \n",
              "2695  و اینک نبی‌ای نزد اخاب، پادشاه اسرائیل آمده، گ...    bible  \n",
              "2696  پس کدامیک از نعمت‌های پروردگارتان را انکار می‌...    quran  \n",
              "2697                     آن قرار و عهد ما بود. بهای آن.    mizan  \n",
              "2698  کلامی که خداوند درباره آمدن نبوکدرصرپادشاه باب...    bible  \n",
              "2699  پس در روز سوم که یوم میلاد فرعون بود، ضیافتی ب...    bible  \n",
              "\n",
              "[2700 rows x 3 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_valid = pd.read_excel('valid.xlsx')\n",
        "df_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "qOdc0TF7Q18_",
        "outputId": "8989aa54-6f13-4e18-9b3c-47626e366001"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bible': 0.33296296296296296,\n",
              " 'mizan': 0.3333333333333333,\n",
              " 'quran': 0.3333333333333333}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "freq_dict = dict()\n",
        "for i in range(1, len(df_valid)):\n",
        "    data = df_valid.iloc[i]\n",
        "    if (data['category'] in freq_dict): freq_dict[data['category']] += 1\n",
        "    else: freq_dict[data['category']] = 1\n",
        "\n",
        "for k,v in freq_dict.items():\n",
        "    freq_dict[k] = v / len(df_valid)\n",
        "\n",
        "sns.countplot(x=df_valid['category'])\n",
        "freq_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TnUyHQLlPPtg",
        "outputId": "6c2c4f1e-e9ab-487e-acbb-47ae21556026"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b121e380-2db3-4a3b-94d0-a43386deb73f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>targets</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The report will cost you five hundred pounds.</td>\n",
              "      <td>اینکار برای شما ۵۰۰لیره خرج برمی دارد.</td>\n",
              "      <td>mizan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>And the cart came into the field of Joshua, a ...</td>\n",
              "      <td>و سموئیل تمامی خاندان اسرائیل را خطاب کرده، گف...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wherefore thus saith the Holy One of Israel, B...</td>\n",
              "      <td>‌ای بنی‌اسرائیل بسوی آن کس که بر وی بینهایت عص...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>For when for the time ye ought to be teachers,...</td>\n",
              "      <td>و این مثلی است برای زمان حاضر که بحسب آن هدایا...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Waited for her to turn</td>\n",
              "      <td>منتظر شدم تا بچرخد</td>\n",
              "      <td>mizan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2695</th>\n",
              "      <td>And the Spirit of God came upon Saul when he h...</td>\n",
              "      <td>وحال اینک پادشاه پیش روی شما راه می‌رود و من پ...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2696</th>\n",
              "      <td>If We had made it an angel, We should have sen...</td>\n",
              "      <td>[این مغالطه گران لجوج می‌گویند: چرا پیامبر از ...</td>\n",
              "      <td>quran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2697</th>\n",
              "      <td>And the Wicked - they will be in the Fire,</td>\n",
              "      <td>و مسلما گناهکاران در دوزخ اند</td>\n",
              "      <td>quran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2698</th>\n",
              "      <td>What was wrong with him then?</td>\n",
              "      <td>مشکلش چیست؟</td>\n",
              "      <td>mizan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2699</th>\n",
              "      <td>And when he had restored the eleven hundred sh...</td>\n",
              "      <td>و آن لاوی راضی شد که با او ساکن شود، و آن جوان...</td>\n",
              "      <td>bible</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2700 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b121e380-2db3-4a3b-94d0-a43386deb73f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b121e380-2db3-4a3b-94d0-a43386deb73f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b121e380-2db3-4a3b-94d0-a43386deb73f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 source  \\\n",
              "0         The report will cost you five hundred pounds.   \n",
              "1     And the cart came into the field of Joshua, a ...   \n",
              "2     Wherefore thus saith the Holy One of Israel, B...   \n",
              "3     For when for the time ye ought to be teachers,...   \n",
              "4                                Waited for her to turn   \n",
              "...                                                 ...   \n",
              "2695  And the Spirit of God came upon Saul when he h...   \n",
              "2696  If We had made it an angel, We should have sen...   \n",
              "2697         And the Wicked - they will be in the Fire,   \n",
              "2698                      What was wrong with him then?   \n",
              "2699  And when he had restored the eleven hundred sh...   \n",
              "\n",
              "                                                targets category  \n",
              "0                اینکار برای شما ۵۰۰لیره خرج برمی دارد.    mizan  \n",
              "1     و سموئیل تمامی خاندان اسرائیل را خطاب کرده، گف...    bible  \n",
              "2     ‌ای بنی‌اسرائیل بسوی آن کس که بر وی بینهایت عص...    bible  \n",
              "3     و این مثلی است برای زمان حاضر که بحسب آن هدایا...    bible  \n",
              "4                                    منتظر شدم تا بچرخد    mizan  \n",
              "...                                                 ...      ...  \n",
              "2695  وحال اینک پادشاه پیش روی شما راه می‌رود و من پ...    bible  \n",
              "2696  [این مغالطه گران لجوج می‌گویند: چرا پیامبر از ...    quran  \n",
              "2697                      و مسلما گناهکاران در دوزخ اند    quran  \n",
              "2698                                        مشکلش چیست؟    mizan  \n",
              "2699  و آن لاوی راضی شد که با او ساکن شود، و آن جوان...    bible  \n",
              "\n",
              "[2700 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = pd.read_excel('test.xlsx')\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "b5cBxRZgQ6rW",
        "outputId": "63147165-98cc-478d-b9a9-aa861fd0ecc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bible': 0.3333333333333333,\n",
              " 'mizan': 0.33296296296296296,\n",
              " 'quran': 0.3333333333333333}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "freq_dict = dict()\n",
        "for i in range(1, len(df_test)):\n",
        "    data = df_test.iloc[i]\n",
        "    if (data['category'] in freq_dict): freq_dict[data['category']] += 1\n",
        "    else: freq_dict[data['category']] = 1\n",
        "\n",
        "for k,v in freq_dict.items():\n",
        "    freq_dict[k] = v / len(df_test)\n",
        "\n",
        "sns.countplot(x=df_test['category'])\n",
        "freq_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Rd-76_vXiHZZ"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_labels=3, dropout_rate=0.):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.linear1 = nn.Linear(input_dim, input_dim // 3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(input_dim // 3, num_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        return self.linear2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bzh226dKTGh5"
      },
      "outputs": [],
      "source": [
        "class BERT(BertModel):\n",
        "    def __init__(self, config, args, label_lst):\n",
        "        super(BERT, self).__init__(config)\n",
        "        self.args = args\n",
        "        self.num_labels = len(set(label_lst))\n",
        "        self.bert = BertModel(config=config) # Load pretrained Bert\n",
        "        self.classifier = Classifier(config.hidden_size, self.num_labels, args.dropout_rate)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids, label_ids):\n",
        "        outputs = self.bert(input_ids, attention_mask, token_type_ids)  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
        "        pooled_output = outputs[1]  # [CLS]\n",
        "        label_logits = self.classifier(pooled_output)\n",
        "\n",
        "        total_loss = 0\n",
        "        # Softmax\n",
        "        if label_ids is not None:\n",
        "            loss = 0\n",
        "            if self.num_labels == 1:\n",
        "                loss_fct = nn.MSELoss()\n",
        "                loss = loss_fct(label_logits.view(-1), label_ids.view(-1))\n",
        "            else:\n",
        "                loss_fct = nn.CrossEntropyLoss()\n",
        "                loss = loss_fct(label_logits.view(-1, self.num_labels), label_ids.view(-1))\n",
        "            total_loss += loss\n",
        "\n",
        "        outputs = (label_logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "        outputs = (total_loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z3kU-vOU6v2k"
      },
      "outputs": [],
      "source": [
        "class PARSBERT(BertModel):\n",
        "    def __init__(self, config, args, label_lst):\n",
        "        super(PARSBERT, self).__init__(config)\n",
        "        self.args = args\n",
        "        self.num_labels = len(set(label_lst))\n",
        "        self.bert = BertModel(config=config) # Load pretrained Bert\n",
        "        self.classifier = Classifier(config.hidden_size, self.num_labels, args.dropout_rate)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids, label_ids):\n",
        "        outputs = self.bert(input_ids, attention_mask, token_type_ids)  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
        "        pooled_output = outputs[1]  # [CLS]\n",
        "        label_logits = self.classifier(pooled_output)\n",
        "\n",
        "        total_loss = 0\n",
        "        # Softmax\n",
        "        if label_ids is not None:\n",
        "            loss = 0\n",
        "            if self.num_labels == 1:\n",
        "                loss_fct = nn.MSELoss()\n",
        "                loss = loss_fct(label_logits.view(-1), label_ids.view(-1))\n",
        "            else:\n",
        "                loss_fct = nn.CrossEntropyLoss()\n",
        "                loss = loss_fct(label_logits.view(-1, self.num_labels), label_ids.view(-1))\n",
        "            total_loss += loss\n",
        "\n",
        "        outputs = (label_logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "        outputs = (total_loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AZqy8gRd679O"
      },
      "outputs": [],
      "source": [
        "class XLMRoBERTa(BertModel):\n",
        "    def __init__(self, config, args, label_lst):\n",
        "        super(XLMRoBERTa, self).__init__(config)\n",
        "        self.args = args\n",
        "        self.num_labels = len(set(label_lst))\n",
        "        self.roberta = XLMRobertaModel(config=config) # Load pretrained Bert\n",
        "        self.classifier = Classifier(config.hidden_size, self.num_labels, args.dropout_rate)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids, label_ids):\n",
        "        outputs = self.roberta(input_ids, attention_mask, token_type_ids)  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
        "        pooled_output = outputs[1]  # [CLS]\n",
        "        label_logits = self.classifier(pooled_output)\n",
        "\n",
        "        total_loss = 0\n",
        "        # Softmax\n",
        "        if label_ids is not None:\n",
        "            loss = 0\n",
        "            if self.num_labels == 1:\n",
        "                loss_fct = nn.MSELoss()\n",
        "                loss = loss_fct(label_logits.view(-1), label_ids.view(-1))\n",
        "            else:\n",
        "                loss_fct = nn.CrossEntropyLoss()\n",
        "                loss = loss_fct(label_logits.view(-1, self.num_labels), label_ids.view(-1))\n",
        "            total_loss += loss\n",
        "\n",
        "        outputs = (label_logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "        outputs = (total_loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JDu_EEZzUCHH"
      },
      "outputs": [],
      "source": [
        "MODEL_CLASSES = {\n",
        "    'XLMRoberta': (XLMRobertaConfig, XLMRoBERTa, XLMRobertaTokenizer),\n",
        "    'parsbert': (BertConfig, PARSBERT, BertTokenizer),\n",
        "    'bert': (BertConfig, BERT, BertTokenizer),\n",
        "}\n",
        "\n",
        "MODEL_PATH_MAP = {\n",
        "    'XLMRoberta': 'xlm-roberta-base',\n",
        "    'bert': 'bert-base-uncased',\n",
        "    'parsbert': 'HooshvareLab/bert-fa-zwnj-base',\n",
        "}\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DZGpOJcyT7hj"
      },
      "outputs": [],
      "source": [
        "def load_tokenizer(args):\n",
        "    return MODEL_CLASSES[args.model_type][2].from_pretrained(args.model_name_or_path)\n",
        "\n",
        "def init_logger():\n",
        "    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                        datefmt='%m/%d/%Y %H:%M:%S',\n",
        "                        level=logging.INFO)\n",
        "    \n",
        "def label2index(label):\n",
        "    if (label == 'quran'): return 0\n",
        "    elif (label == 'bible'): return 1\n",
        "    else: return 2\n",
        "\n",
        "def get_labels(dataset):\n",
        "  train_label = list()\n",
        "  for i in range(len(dataset)):\n",
        "      data = dataset.iloc[i]\n",
        "      train_label.append(data['category'])\n",
        "  \n",
        "  return train_label\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if not args.no_cuda and torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(args.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "c80tf2kyUdz9"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(data, col, args, tokenizer, padding='max_length'):\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    all_label = torch.tensor(data['category'].apply(label2index), dtype=torch.long).to(device)\n",
        "    if (len(col) > 1):\n",
        "        bert_input = tokenizer(list(data[col[0]]), list(data[col[1]]), padding=padding, max_length=args.max_seq_len, truncation=True, return_tensors=\"pt\")\n",
        "        dataset = TensorDataset(bert_input['input_ids'].to(device), bert_input['attention_mask'].to(device), torch.zeros_like(bert_input['input_ids']).to(device), all_label)\n",
        "    else:\n",
        "        bert_input = tokenizer(list(data[col[0]]), padding=padding, max_length=args.max_seq_len, truncation=True, return_tensors=\"pt\")\n",
        "        if ('token_type_ids' in bert_input):\n",
        "            dataset = TensorDataset(bert_input['input_ids'].to(device), bert_input['attention_mask'].to(device), bert_input['token_type_ids'].to(device), all_label)\n",
        "        else:\n",
        "            dataset = TensorDataset(bert_input['input_ids'].to(device), bert_input['attention_mask'].to(device), torch.zeros_like(bert_input['input_ids']).to(device), all_label)\n",
        "     \n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_YAwqf72UbHI"
      },
      "outputs": [],
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, args, train_dataset=None, dev_dataset=None, test_dataset=None):\n",
        "        self.args = args\n",
        "        self.train_dataset = train_dataset\n",
        "        self.dev_dataset = dev_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "\n",
        "        self.label_lst = get_labels(df_train)\n",
        "\n",
        "        self.config_class, self.model_class, _ = MODEL_CLASSES[args.model_type]\n",
        "        self.config = self.config_class.from_pretrained(args.model_name_or_path, finetuning_task=args.task)\n",
        "        self.model = self.model_class.from_pretrained(args.model_name_or_path,\n",
        "                                                      config=self.config,\n",
        "                                                      args=args,\n",
        "                                                      label_lst=self.label_lst)\n",
        "                                                      \n",
        "\n",
        "        # GPU or CPU\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def train(self):\n",
        "        train_sampler = RandomSampler(self.train_dataset)\n",
        "        train_dataloader = DataLoader(self.train_dataset, sampler=train_sampler, batch_size=self.args.train_batch_size)\n",
        "        if self.args.max_steps > 0:\n",
        "            t_total = self.args.max_steps\n",
        "            self.args.num_train_epochs = self.args.max_steps // (len(train_dataloader) // self.args.gradient_accumulation_steps) + 1\n",
        "        else:\n",
        "            t_total = len(train_dataloader) // self.args.gradient_accumulation_steps * self.args.num_train_epochs\n",
        "\n",
        "        # Prepare optimizer and schedule (linear warmup and decay)\n",
        "        no_decay = ['bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'weight_decay': self.args.weight_decay},\n",
        "            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate, eps=self.args.adam_epsilon)\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=self.args.warmup_steps, num_training_steps=t_total)\n",
        "\n",
        "        # Train!\n",
        "        logger.info(\"***** Running training *****\")\n",
        "        logger.info(\"  Num examples = %d\", len(self.train_dataset))\n",
        "        logger.info(\"  Num Epochs = %d\", self.args.num_train_epochs)\n",
        "        logger.info(\"  Total train batch size = %d\", self.args.train_batch_size)\n",
        "        logger.info(\"  Gradient Accumulation steps = %d\", self.args.gradient_accumulation_steps)\n",
        "        logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "        logger.info(\"  Logging steps = %d\", self.args.logging_steps)\n",
        "        logger.info(\"  Save steps = %d\", self.args.save_steps)\n",
        "\n",
        "        global_step = 0\n",
        "        tr_loss = 0.0\n",
        "        self.model.zero_grad()\n",
        "        best_acc = -1\n",
        "       \n",
        "        train_iterator = trange(int(self.args.num_train_epochs), desc=\"Epoch\")\n",
        "        for _ in train_iterator:\n",
        "            label_preds = None\n",
        "            out_label_ids = None\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                self.model.train()\n",
        "                inputs = {'input_ids': batch[0],\n",
        "                          'attention_mask': batch[1],\n",
        "                          'token_type_ids': batch[2],\n",
        "                          'label_ids': batch[3]}\n",
        "                outputs = self.model(**inputs)\n",
        "                loss = outputs[0]\n",
        "                label_logits = outputs[1]\n",
        "\n",
        "                 # label prediction\n",
        "                if label_preds is None:\n",
        "                    label_preds = label_logits.detach().cpu().numpy()\n",
        "                    out_label_ids = inputs['label_ids'].detach().cpu().numpy()\n",
        "                else:\n",
        "                    label_preds = np.append(label_preds, label_logits.detach().cpu().numpy(), axis=0)\n",
        "                    out_label_ids = np.append(out_label_ids, inputs['label_ids'].detach().cpu().numpy(), axis=0)\n",
        "                \n",
        "                if self.args.gradient_accumulation_steps > 1:\n",
        "                    loss = loss / self.args.gradient_accumulation_steps\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                tr_loss += loss.item()\n",
        "                if (step + 1) % self.args.gradient_accumulation_steps == 0:\n",
        "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.max_grad_norm)\n",
        "\n",
        "                    optimizer.step()\n",
        "                    scheduler.step()  # Update learning rate schedule\n",
        "                    self.model.zero_grad()\n",
        "                    global_step += 1\n",
        "\n",
        "                    if(global_step % 50 == 0): logger.info(\"Train loss = %.4f\", tr_loss / global_step)\n",
        "                    if (self.args.logging_steps > 0 and global_step % self.args.logging_steps == 0):\n",
        "                        results = self.evaluate(\"dev\")\n",
        "                        if (float(results['accuracy']) > best_acc):\n",
        "                          best_acc = float(results['accuracy'])\n",
        "                          logger.info(\"valid best_acc = %.4f\", best_acc * 100.0)\n",
        "                          self.save_model()\n",
        "\n",
        "                  \n",
        "            if 0 < self.args.max_steps < global_step:\n",
        "                train_iterator.close()\n",
        "                break\n",
        "            \n",
        "            # label result\n",
        "            label_preds = np.argmax(label_preds, axis=1)\n",
        "            logger.info(\"train_acc = %.4f\", accuracy_score(out_label_ids, label_preds) * 100.0)\n",
        "\n",
        "\n",
        "\n",
        "        return global_step, tr_loss / global_step\n",
        "\n",
        "    def evaluate(self, mode):\n",
        "        if mode == 'test':\n",
        "            dataset = self.test_dataset\n",
        "        elif mode == 'dev':\n",
        "            dataset = self.dev_dataset\n",
        "        else:\n",
        "            raise Exception(\"Only dev and test dataset available\")\n",
        "\n",
        "        eval_sampler = SequentialSampler(dataset)\n",
        "        eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=self.args.eval_batch_size)\n",
        "\n",
        "        # Eval!\n",
        "        logger.info(\"\\n***** Running evaluation on %s dataset *****\", mode)\n",
        "        logger.info(\"  Num examples = %d\", len(dataset))\n",
        "        logger.info(\"  Batch size = %d\", self.args.eval_batch_size)\n",
        "        eval_loss = 0.0\n",
        "        nb_eval_steps = 0\n",
        "        label_preds = None\n",
        "        out_label_ids = None\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        # for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        for batch in eval_dataloader:\n",
        "            batch = tuple(t.to(self.device) for t in batch)\n",
        "            with torch.no_grad():\n",
        "                inputs = {'input_ids': batch[0],\n",
        "                          'attention_mask': batch[1],\n",
        "                          'token_type_ids': batch[2],\n",
        "                          'label_ids': batch[3]}\n",
        "                outputs = self.model(**inputs)\n",
        "                tmp_eval_loss, label_logits = outputs[:2]\n",
        "                eval_loss += tmp_eval_loss.mean().item()\n",
        "            \n",
        "            nb_eval_steps += 1\n",
        "\n",
        "            # label prediction\n",
        "            if label_preds is None:\n",
        "                label_preds = label_logits.detach().cpu().numpy()\n",
        "                out_label_ids = inputs['label_ids'].detach().cpu().numpy()\n",
        "            else:\n",
        "                label_preds = np.append(label_preds, label_logits.detach().cpu().numpy(), axis=0)\n",
        "                out_label_ids = np.append(out_label_ids, inputs['label_ids'].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        results = {\n",
        "            \"loss\": eval_loss\n",
        "        }\n",
        "\n",
        "        # label result\n",
        "        m = nn.Softmax(dim = 1)\n",
        "        temp_preds = m(torch.Tensor(label_preds))\n",
        "        label_preds = np.argmax(label_preds, axis=1)\n",
        "        total_result = accuracy_score(out_label_ids, label_preds)\n",
        "        results.update({'accuracy' : total_result})\n",
        "        logger.info(\"***** Eval results *****\")\n",
        "        for key in sorted(results.keys()):\n",
        "            logger.info(\"  %s = %.4f\", key if key != 'loss' else 'loss', float(results[key]) * 100.0 if key != 'loss' else float(results[key]))\n",
        "\n",
        "        if (mode == 'test'): \n",
        "          print(classification_report(out_label_ids, label_preds, target_names=['quran', 'bible', 'mizan'], digits = 4))\n",
        "          print(('AUC = %.4f') % (roc_auc_score(out_label_ids, temp_preds, average = 'macro', multi_class = 'ovr')))\n",
        "        return results\n",
        "\n",
        "    def save_model(self):\n",
        "        # Save model checkpoint (Overwrite)\n",
        "        if not os.path.exists(self.args.model_dir):\n",
        "            os.makedirs(self.args.model_dir)\n",
        "        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model\n",
        "        model_to_save.save_pretrained(self.args.model_dir)\n",
        "\n",
        "     \n",
        "    def load_model(self):\n",
        "        # Check whether model exists\n",
        "        if not os.path.exists(self.args.model_dir):\n",
        "            raise Exception(\"Model doesn't exists! Train first!\")\n",
        "\n",
        "        try:\n",
        "            self.model = self.model_class.from_pretrained(self.args.model_dir,\n",
        "                                                        #   config=self.config,\n",
        "                                                          args=self.args,\n",
        "                                                          label_lst=self.label_lst)\n",
        "            self.model.to(self.device)\n",
        "            logger.info(\"***** Model Loaded *****\")\n",
        "        except:\n",
        "            raise Exception(\"Some model files might be missing...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "figpxYuoV8C6"
      },
      "outputs": [],
      "source": [
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNvfBc3pLgzL"
      },
      "source": [
        "XLMRoberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-W7n6hgxV8yo"
      },
      "outputs": [],
      "source": [
        "args = dotdict(dict())\n",
        "args.seed = 810197502 # to make results reproducible\n",
        "args.model_type = 'XLMRoberta' \n",
        "args.model_name_or_path = MODEL_PATH_MAP[args.model_type]\n",
        "args.dropout_rate =  0.2\n",
        "args.do_train = True\n",
        "args.do_eval = True\n",
        "args.train_batch_size = 32 \n",
        "args.max_steps = -1\n",
        "args.task = 'Classification' \n",
        "args.no_cuda = False\n",
        "args.weight_decay = 0\n",
        "args.num_train_epochs = 10\n",
        "args.gradient_accumulation_steps = 1 \n",
        "args.learning_rate = 3e-5 \n",
        "args.adam_epsilon = 1e-8\n",
        "args.warmup_steps = 0 \n",
        "args.logging_steps = 500\n",
        "args.save_steps = 500\n",
        "args.max_grad_norm = 1\n",
        "args.eval_batch_size = 32\n",
        "args.model_dir = \"Model_\" + args.model_type\n",
        "args.max_seq_len = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQnPgJ54cn51"
      },
      "source": [
        "English training using XLMRoberta and evaluating on Persian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "63f5f2c956ba42cf9d0a7f5300908c77",
            "8ed24253d5554efb943960000af3b0af",
            "ed400d78ffc94a4ba388923d3430c50f",
            "5ed747458a6d4703be743a66a4421290",
            "2d1a1de8f2c64cf1a0bb5097b074cde7",
            "78ab75feffb04b1788f3986e76d8d409",
            "98124da361654c049c939a8398411951",
            "9286a9ea808c4fcfb3dcf47acf82f3cc",
            "7b299dac695144f8a9961793726ed7eb",
            "e7d67d75d1be4902bd13aa2dc0db3b00",
            "794f5e298b4c48f3b4dece348a911b55",
            "1382ef788a08495b8ad5a01f11e9cb7a",
            "beb73c5994044e698c6b4bcc35add33d",
            "a916b46fb3724676ae9b4e6daa5cf022",
            "12b41dbb06e5493c8a63da70c9ecf0d5",
            "07487b61bcca4634a41d4ac465145c47",
            "d544bff78a3d4d878deb3d963a786574",
            "605b06d206174e44ae304996c4649503",
            "f8ceaca667de4993b1adfbd2f673d605",
            "6a602e4ca995417d99e7642aa09fb6a5",
            "2fbe7501e0244ca1b16c0d6ce2d810e1",
            "c7b38e71b0d44597a12f28e9e422608c"
          ]
        },
        "id": "vIMUir0YKvoo",
        "outputId": "de2952af-07c0-4a86-b429-c47869dffeb4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63f5f2c956ba42cf9d0a7f5300908c77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1382ef788a08495b8ad5a01f11e9cb7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# english with XLMRoberta\n",
        "init_logger()\n",
        "set_seed(args)\n",
        "tokenizer = load_tokenizer(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "R4RF4KYgK2y7"
      },
      "outputs": [],
      "source": [
        "col = ['source']\n",
        "train_dataset = prepare_dataset(df_train, col, args, tokenizer)\n",
        "valid_dataset = prepare_dataset(df_valid, col, args, tokenizer)\n",
        "col = ['targets']\n",
        "test_dataset = prepare_dataset(df_test, col, args, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "ec9458f056d44517a8c534b489564f4b",
            "591077736b3e4a7b9c749d2619ae3244",
            "c15a74ccc910441a8ed3b1b5d93ff90e",
            "ad839379ced843c0a87278538fe02613",
            "5936ccaca6824eb58d8b9e85cf943ba7",
            "be286ecd5b3d40cda79c6cb779a5eff9",
            "ada8fefcea25400db347678032206b91",
            "f4a496a656554ca89f59f1691646cfb3",
            "589715a05e514467a3e818e1097b6b18",
            "82d3fc56931b49b6a115aef2cc4294f1",
            "45fc3064ad384639b3e4812f7289094a"
          ]
        },
        "id": "zsy9Ve-fK6Ho",
        "outputId": "9120e508-8fe3-400e-8287-32b80d5c53ad"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec9458f056d44517a8c534b489564f4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRoBERTa: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing XLMRoBERTa from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRoBERTa from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRoBERTa were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'classifier.linear2.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'classifier.linear2.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'classifier.linear1.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'classifier.linear1.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(args, train_dataset, valid_dataset, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQnttktcLMfw",
        "outputId": "387ca947-ee76-44fd-cdac-781cff6cf2b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "05/25/2022 06:37:40 - INFO - __main__ -   ***** Running training *****\n",
            "05/25/2022 06:37:40 - INFO - __main__ -     Num examples = 12600\n",
            "05/25/2022 06:37:40 - INFO - __main__ -     Num Epochs = 10\n",
            "05/25/2022 06:37:40 - INFO - __main__ -     Total train batch size = 32\n",
            "05/25/2022 06:37:40 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "05/25/2022 06:37:40 - INFO - __main__ -     Total optimization steps = 3940\n",
            "05/25/2022 06:37:40 - INFO - __main__ -     Logging steps = 500\n",
            "05/25/2022 06:37:40 - INFO - __main__ -     Save steps = 500\n",
            "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]05/25/2022 06:38:14 - INFO - __main__ -   Train loss = 0.9441\n",
            "05/25/2022 06:38:48 - INFO - __main__ -   Train loss = 0.7351\n",
            "05/25/2022 06:39:23 - INFO - __main__ -   Train loss = 0.5950\n",
            "05/25/2022 06:39:59 - INFO - __main__ -   Train loss = 0.5074\n",
            "05/25/2022 06:40:35 - INFO - __main__ -   Train loss = 0.4464\n",
            "05/25/2022 06:41:12 - INFO - __main__ -   Train loss = 0.3960\n",
            "05/25/2022 06:41:48 - INFO - __main__ -   Train loss = 0.3679\n",
            "05/25/2022 06:42:20 - INFO - __main__ -   train_acc = 89.0794\n",
            "Epoch:  10%|█         | 1/10 [04:40<42:01, 280.21s/it]05/25/2022 06:42:25 - INFO - __main__ -   Train loss = 0.3415\n",
            "05/25/2022 06:43:02 - INFO - __main__ -   Train loss = 0.3152\n",
            "05/25/2022 06:43:39 - INFO - __main__ -   Train loss = 0.2968\n",
            "05/25/2022 06:43:39 - INFO - __main__ -   \n",
            "***** Running evaluation on dev dataset *****\n",
            "05/25/2022 06:43:39 - INFO - __main__ -     Num examples = 2700\n",
            "05/25/2022 06:43:39 - INFO - __main__ -     Batch size = 32\n",
            "05/25/2022 06:43:58 - INFO - __main__ -   ***** Eval results *****\n",
            "05/25/2022 06:43:58 - INFO - __main__ -     accuracy = 96.9259\n",
            "05/25/2022 06:43:58 - INFO - __main__ -     loss = 0.1232\n",
            "05/25/2022 06:43:58 - INFO - __main__ -   valid best_acc = 96.9259\n",
            "05/25/2022 06:44:44 - INFO - __main__ -   Train loss = 0.2784\n",
            "05/25/2022 06:45:22 - INFO - __main__ -   Train loss = 0.2650\n",
            "05/25/2022 06:45:59 - INFO - __main__ -   Train loss = 0.2524\n",
            "05/25/2022 06:46:36 - INFO - __main__ -   Train loss = 0.2401\n",
            "05/25/2022 06:47:13 - INFO - __main__ -   Train loss = 0.2318\n",
            "05/25/2022 06:47:41 - INFO - __main__ -   train_acc = 97.1984\n",
            "Epoch:  20%|██        | 2/10 [10:00<40:32, 304.01s/it]05/25/2022 06:47:50 - INFO - __main__ -   Train loss = 0.2234\n",
            "05/25/2022 06:48:27 - INFO - __main__ -   Train loss = 0.2142\n",
            "05/25/2022 06:49:04 - INFO - __main__ -   Train loss = 0.2073\n",
            "05/25/2022 06:49:41 - INFO - __main__ -   Train loss = 0.2006\n",
            "05/25/2022 06:50:18 - INFO - __main__ -   Train loss = 0.1936\n",
            "05/25/2022 06:50:18 - INFO - __main__ -   \n",
            "***** Running evaluation on dev dataset *****\n",
            "05/25/2022 06:50:18 - INFO - __main__ -     Num examples = 2700\n",
            "05/25/2022 06:50:18 - INFO - __main__ -     Batch size = 32\n",
            "05/25/2022 06:50:37 - INFO - __main__ -   ***** Eval results *****\n",
            "05/25/2022 06:50:37 - INFO - __main__ -     accuracy = 97.8148\n",
            "05/25/2022 06:50:37 - INFO - __main__ -     loss = 0.1068\n",
            "05/25/2022 06:50:37 - INFO - __main__ -   valid best_acc = 97.8148\n",
            "05/25/2022 06:51:24 - INFO - __main__ -   Train loss = 0.1873\n",
            "05/25/2022 06:52:01 - INFO - __main__ -   Train loss = 0.1807\n",
            "05/25/2022 06:52:38 - INFO - __main__ -   Train loss = 0.1757\n",
            "05/25/2022 06:53:02 - INFO - __main__ -   train_acc = 98.4206\n",
            "Epoch:  30%|███       | 3/10 [15:21<36:21, 311.64s/it]05/25/2022 06:53:15 - INFO - __main__ -   Train loss = 0.1705\n",
            "05/25/2022 06:53:52 - INFO - __main__ -   Train loss = 0.1654\n",
            "05/25/2022 06:54:29 - INFO - __main__ -   Train loss = 0.1609\n",
            "05/25/2022 06:55:07 - INFO - __main__ -   Train loss = 0.1570\n",
            "05/25/2022 06:55:44 - INFO - __main__ -   Train loss = 0.1527\n",
            "05/25/2022 06:56:21 - INFO - __main__ -   Train loss = 0.1486\n",
            "05/25/2022 06:56:58 - INFO - __main__ -   Train loss = 0.1445\n",
            "05/25/2022 06:56:58 - INFO - __main__ -   \n",
            "***** Running evaluation on dev dataset *****\n",
            "05/25/2022 06:56:58 - INFO - __main__ -     Num examples = 2700\n",
            "05/25/2022 06:56:58 - INFO - __main__ -     Batch size = 32\n",
            "05/25/2022 06:57:16 - INFO - __main__ -   ***** Eval results *****\n",
            "05/25/2022 06:57:16 - INFO - __main__ -     accuracy = 97.7407\n",
            "05/25/2022 06:57:16 - INFO - __main__ -     loss = 0.1203\n",
            "05/25/2022 06:57:53 - INFO - __main__ -   Train loss = 0.1418\n",
            "05/25/2022 06:58:13 - INFO - __main__ -   train_acc = 99.0238\n",
            "Epoch:  40%|████      | 4/10 [20:32<31:07, 311.31s/it]05/25/2022 06:58:30 - INFO - __main__ -   Train loss = 0.1385\n",
            "05/25/2022 06:59:07 - INFO - __main__ -   Train loss = 0.1351\n",
            "05/25/2022 06:59:44 - INFO - __main__ -   Train loss = 0.1324\n",
            "05/25/2022 07:00:22 - INFO - __main__ -   Train loss = 0.1293\n",
            "05/25/2022 07:00:59 - INFO - __main__ -   Train loss = 0.1261\n",
            "05/25/2022 07:01:36 - INFO - __main__ -   Train loss = 0.1235\n",
            "05/25/2022 07:02:13 - INFO - __main__ -   Train loss = 0.1205\n",
            "05/25/2022 07:02:50 - INFO - __main__ -   Train loss = 0.1181\n",
            "05/25/2022 07:03:05 - INFO - __main__ -   train_acc = 99.5317\n",
            "Epoch:  50%|█████     | 5/10 [25:24<25:21, 304.35s/it]05/25/2022 07:03:27 - INFO - __main__ -   Train loss = 0.1156\n",
            "05/25/2022 07:03:27 - INFO - __main__ -   \n",
            "***** Running evaluation on dev dataset *****\n",
            "05/25/2022 07:03:27 - INFO - __main__ -     Num examples = 2700\n",
            "05/25/2022 07:03:27 - INFO - __main__ -     Batch size = 32\n",
            "05/25/2022 07:03:45 - INFO - __main__ -   ***** Eval results *****\n",
            "05/25/2022 07:03:45 - INFO - __main__ -     accuracy = 98.2963\n",
            "05/25/2022 07:03:45 - INFO - __main__ -     loss = 0.0998\n",
            "05/25/2022 07:03:45 - INFO - __main__ -   valid best_acc = 98.2963\n",
            "05/25/2022 07:04:32 - INFO - __main__ -   Train loss = 0.1131\n",
            "05/25/2022 07:05:09 - INFO - __main__ -   Train loss = 0.1108\n",
            "05/25/2022 07:05:46 - INFO - __main__ -   Train loss = 0.1084\n",
            "05/25/2022 07:06:24 - INFO - __main__ -   Train loss = 0.1062\n",
            "05/25/2022 07:07:01 - INFO - __main__ -   Train loss = 0.1040\n",
            "05/25/2022 07:07:38 - INFO - __main__ -   Train loss = 0.1020\n",
            "05/25/2022 07:08:15 - INFO - __main__ -   Train loss = 0.0999\n",
            "05/25/2022 07:08:25 - INFO - __main__ -   train_acc = 99.7857\n",
            "Epoch:  60%|██████    | 6/10 [30:44<20:39, 309.84s/it]05/25/2022 07:08:52 - INFO - __main__ -   Train loss = 0.0980\n",
            "05/25/2022 07:09:29 - INFO - __main__ -   Train loss = 0.0964\n",
            "05/25/2022 07:10:06 - INFO - __main__ -   Train loss = 0.0949\n",
            "05/25/2022 07:10:06 - INFO - __main__ -   \n",
            "***** Running evaluation on dev dataset *****\n",
            "05/25/2022 07:10:06 - INFO - __main__ -     Num examples = 2700\n",
            "05/25/2022 07:10:06 - INFO - __main__ -     Batch size = 32\n",
            "05/25/2022 07:10:25 - INFO - __main__ -   ***** Eval results *****\n",
            "05/25/2022 07:10:25 - INFO - __main__ -     accuracy = 98.2593\n",
            "05/25/2022 07:10:25 - INFO - __main__ -     loss = 0.1120\n",
            "05/25/2022 07:11:02 - INFO - __main__ -   Train loss = 0.0931\n",
            "05/25/2022 07:11:39 - INFO - __main__ -   Train loss = 0.0914\n",
            "05/25/2022 07:12:16 - INFO - __main__ -   Train loss = 0.0898\n",
            "05/25/2022 07:12:53 - INFO - __main__ -   Train loss = 0.0884\n",
            "05/25/2022 07:13:30 - INFO - __main__ -   Train loss = 0.0868\n",
            "05/25/2022 07:13:36 - INFO - __main__ -   train_acc = 99.8175\n",
            "Epoch:  70%|███████   | 7/10 [35:55<15:30, 310.14s/it]05/25/2022 07:14:07 - INFO - __main__ -   Train loss = 0.0853\n",
            "05/25/2022 07:14:44 - INFO - __main__ -   Train loss = 0.0839\n",
            "05/25/2022 07:15:21 - INFO - __main__ -   Train loss = 0.0826\n",
            "05/25/2022 07:15:58 - INFO - __main__ -   Train loss = 0.0812\n",
            "05/25/2022 07:16:35 - INFO - __main__ -   Train loss = 0.0801\n",
            "05/25/2022 07:16:35 - INFO - __main__ -   \n",
            "***** Running evaluation on dev dataset *****\n",
            "05/25/2022 07:16:35 - INFO - __main__ -     Num examples = 2700\n",
            "05/25/2022 07:16:35 - INFO - __main__ -     Batch size = 32\n",
            "05/25/2022 07:16:54 - INFO - __main__ -   ***** Eval results *****\n",
            "05/25/2022 07:16:54 - INFO - __main__ -     accuracy = 98.1481\n",
            "05/25/2022 07:16:54 - INFO - __main__ -     loss = 0.1251\n",
            "05/25/2022 07:17:31 - INFO - __main__ -   Train loss = 0.0788\n",
            "05/25/2022 07:18:08 - INFO - __main__ -   Train loss = 0.0777\n",
            "05/25/2022 07:18:45 - INFO - __main__ -   Train loss = 0.0766\n",
            "05/25/2022 07:18:47 - INFO - __main__ -   train_acc = 99.8651\n",
            "Epoch:  80%|████████  | 8/10 [41:06<10:20, 310.38s/it]05/25/2022 07:19:22 - INFO - __main__ -   Train loss = 0.0755\n",
            "05/25/2022 07:19:59 - INFO - __main__ -   Train loss = 0.0743\n",
            "05/25/2022 07:20:36 - INFO - __main__ -   Train loss = 0.0733\n",
            "05/25/2022 07:21:13 - INFO - __main__ -   Train loss = 0.0722\n",
            "05/25/2022 07:21:51 - INFO - __main__ -   Train loss = 0.0712\n",
            "05/25/2022 07:22:28 - INFO - __main__ -   Train loss = 0.0701\n",
            "05/25/2022 07:23:05 - INFO - __main__ -   Train loss = 0.0692\n",
            "05/25/2022 07:23:05 - INFO - __main__ -   \n",
            "***** Running evaluation on dev dataset *****\n",
            "05/25/2022 07:23:05 - INFO - __main__ -     Num examples = 2700\n",
            "05/25/2022 07:23:05 - INFO - __main__ -     Batch size = 32\n",
            "05/25/2022 07:23:23 - INFO - __main__ -   ***** Eval results *****\n",
            "05/25/2022 07:23:23 - INFO - __main__ -     accuracy = 98.1481\n",
            "05/25/2022 07:23:23 - INFO - __main__ -     loss = 0.1288\n",
            "05/25/2022 07:23:57 - INFO - __main__ -   train_acc = 99.9524\n",
            "Epoch:  90%|█████████ | 9/10 [46:17<05:10, 310.43s/it]05/25/2022 07:24:00 - INFO - __main__ -   Train loss = 0.0682\n",
            "05/25/2022 07:24:37 - INFO - __main__ -   Train loss = 0.0673\n",
            "05/25/2022 07:25:14 - INFO - __main__ -   Train loss = 0.0664\n",
            "05/25/2022 07:25:51 - INFO - __main__ -   Train loss = 0.0655\n",
            "05/25/2022 07:26:28 - INFO - __main__ -   Train loss = 0.0647\n",
            "05/25/2022 07:27:06 - INFO - __main__ -   Train loss = 0.0639\n",
            "05/25/2022 07:27:43 - INFO - __main__ -   Train loss = 0.0631\n",
            "05/25/2022 07:28:20 - INFO - __main__ -   Train loss = 0.0623\n",
            "05/25/2022 07:28:49 - INFO - __main__ -   train_acc = 99.9603\n",
            "Epoch: 100%|██████████| 10/10 [51:09<00:00, 306.90s/it]\n",
            "05/25/2022 07:28:49 - INFO - __main__ -   \n",
            "***** Running evaluation on test dataset *****\n",
            "05/25/2022 07:28:49 - INFO - __main__ -     Num examples = 2700\n",
            "05/25/2022 07:28:49 - INFO - __main__ -     Batch size = 32\n",
            "05/25/2022 07:29:08 - INFO - __main__ -   ***** Eval results *****\n",
            "05/25/2022 07:29:08 - INFO - __main__ -     accuracy = 75.8519\n",
            "05/25/2022 07:29:08 - INFO - __main__ -     loss = 2.0242\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       quran     0.7908    0.7600    0.7751       900\n",
            "       bible     0.8377    0.5389    0.6558       900\n",
            "       mizan     0.6998    0.9767    0.8154       900\n",
            "\n",
            "    accuracy                         0.7585      2700\n",
            "   macro avg     0.7761    0.7585    0.7488      2700\n",
            "weighted avg     0.7761    0.7585    0.7488      2700\n",
            "\n",
            "AUC = 0.9117\n"
          ]
        }
      ],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "if args.do_train:\n",
        "    # trainer.load_model()\n",
        "    trainer.train()\n",
        "\n",
        "if args.do_eval:\n",
        "    # trainer.load_model()\n",
        "    trainer.evaluate(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOHbNr90JB6F",
        "outputId": "a51594be-2a11-458d-c0f2-5531a595fd52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRoBERTa: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRoBERTa from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRoBERTa from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRoBERTa were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['encoder.layer.2.attention.self.query.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'classifier.linear2.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'classifier.linear2.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'classifier.linear1.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'classifier.linear1.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "args.num_train_epochs = 1\n",
        "trainer = Trainer(args, train_dataset, valid_dataset, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kesvnyEcJJ0_",
        "outputId": "e9af67e7-a741-4947-94d0-20ffde880232"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "05/25/2022 08:07:43 - INFO - __main__ -   ***** Running training *****\n",
            "05/25/2022 08:07:43 - INFO - __main__ -     Num examples = 12600\n",
            "05/25/2022 08:07:43 - INFO - __main__ -     Num Epochs = 1\n",
            "05/25/2022 08:07:43 - INFO - __main__ -     Total train batch size = 32\n",
            "05/25/2022 08:07:43 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "05/25/2022 08:07:43 - INFO - __main__ -     Total optimization steps = 394\n",
            "05/25/2022 08:07:43 - INFO - __main__ -     Logging steps = 500\n",
            "05/25/2022 08:07:43 - INFO - __main__ -     Save steps = 500\n",
            "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]05/25/2022 08:08:19 - INFO - __main__ -   Train loss = 0.9739\n",
            "05/25/2022 08:08:55 - INFO - __main__ -   Train loss = 0.8205\n",
            "05/25/2022 08:09:31 - INFO - __main__ -   Train loss = 0.6889\n",
            "05/25/2022 08:10:06 - INFO - __main__ -   Train loss = 0.5836\n",
            "05/25/2022 08:10:42 - INFO - __main__ -   Train loss = 0.5101\n",
            "05/25/2022 08:11:18 - INFO - __main__ -   Train loss = 0.4545\n",
            "05/25/2022 08:11:54 - INFO - __main__ -   Train loss = 0.4103\n",
            "05/25/2022 08:12:25 - INFO - __main__ -   train_acc = 87.9603\n",
            "Epoch: 100%|██████████| 1/1 [04:42<00:00, 282.22s/it]\n",
            "05/25/2022 08:12:25 - INFO - __main__ -   \n",
            "***** Running evaluation on test dataset *****\n",
            "05/25/2022 08:12:25 - INFO - __main__ -     Num examples = 2700\n",
            "05/25/2022 08:12:25 - INFO - __main__ -     Batch size = 32\n",
            "05/25/2022 08:12:43 - INFO - __main__ -   ***** Eval results *****\n",
            "05/25/2022 08:12:43 - INFO - __main__ -     accuracy = 82.1111\n",
            "05/25/2022 08:12:43 - INFO - __main__ -     loss = 0.5719\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       quran     0.8018    0.8000    0.8009       900\n",
            "       bible     0.8183    0.7056    0.7578       900\n",
            "       mizan     0.8402    0.9578    0.8951       900\n",
            "\n",
            "    accuracy                         0.8211      2700\n",
            "   macro avg     0.8201    0.8211    0.8179      2700\n",
            "weighted avg     0.8201    0.8211    0.8179      2700\n",
            "\n",
            "AUC = 0.9394\n"
          ]
        }
      ],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "if args.do_train:\n",
        "    # trainer.load_model()\n",
        "    trainer.train()\n",
        "\n",
        "if args.do_eval:\n",
        "    # trainer.load_model()\n",
        "    trainer.evaluate(\"test\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CA4_part3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07487b61bcca4634a41d4ac465145c47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b41dbb06e5493c8a63da70c9ecf0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fbe7501e0244ca1b16c0d6ce2d810e1",
            "placeholder": "​",
            "style": "IPY_MODEL_c7b38e71b0d44597a12f28e9e422608c",
            "value": " 615/615 [00:00&lt;00:00, 18.6kB/s]"
          }
        },
        "1382ef788a08495b8ad5a01f11e9cb7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beb73c5994044e698c6b4bcc35add33d",
              "IPY_MODEL_a916b46fb3724676ae9b4e6daa5cf022",
              "IPY_MODEL_12b41dbb06e5493c8a63da70c9ecf0d5"
            ],
            "layout": "IPY_MODEL_07487b61bcca4634a41d4ac465145c47"
          }
        },
        "2d1a1de8f2c64cf1a0bb5097b074cde7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fbe7501e0244ca1b16c0d6ce2d810e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45fc3064ad384639b3e4812f7289094a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "589715a05e514467a3e818e1097b6b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "591077736b3e4a7b9c749d2619ae3244": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be286ecd5b3d40cda79c6cb779a5eff9",
            "placeholder": "​",
            "style": "IPY_MODEL_ada8fefcea25400db347678032206b91",
            "value": "Downloading: 100%"
          }
        },
        "5936ccaca6824eb58d8b9e85cf943ba7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ed747458a6d4703be743a66a4421290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d67d75d1be4902bd13aa2dc0db3b00",
            "placeholder": "​",
            "style": "IPY_MODEL_794f5e298b4c48f3b4dece348a911b55",
            "value": " 4.83M/4.83M [00:00&lt;00:00, 23.2MB/s]"
          }
        },
        "605b06d206174e44ae304996c4649503": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63f5f2c956ba42cf9d0a7f5300908c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ed24253d5554efb943960000af3b0af",
              "IPY_MODEL_ed400d78ffc94a4ba388923d3430c50f",
              "IPY_MODEL_5ed747458a6d4703be743a66a4421290"
            ],
            "layout": "IPY_MODEL_2d1a1de8f2c64cf1a0bb5097b074cde7"
          }
        },
        "6a602e4ca995417d99e7642aa09fb6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78ab75feffb04b1788f3986e76d8d409": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794f5e298b4c48f3b4dece348a911b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b299dac695144f8a9961793726ed7eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82d3fc56931b49b6a115aef2cc4294f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed24253d5554efb943960000af3b0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78ab75feffb04b1788f3986e76d8d409",
            "placeholder": "​",
            "style": "IPY_MODEL_98124da361654c049c939a8398411951",
            "value": "Downloading: 100%"
          }
        },
        "9286a9ea808c4fcfb3dcf47acf82f3cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98124da361654c049c939a8398411951": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a916b46fb3724676ae9b4e6daa5cf022": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ceaca667de4993b1adfbd2f673d605",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a602e4ca995417d99e7642aa09fb6a5",
            "value": 615
          }
        },
        "ad839379ced843c0a87278538fe02613": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82d3fc56931b49b6a115aef2cc4294f1",
            "placeholder": "​",
            "style": "IPY_MODEL_45fc3064ad384639b3e4812f7289094a",
            "value": " 1.04G/1.04G [01:01&lt;00:00, 56.5MB/s]"
          }
        },
        "ada8fefcea25400db347678032206b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be286ecd5b3d40cda79c6cb779a5eff9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb73c5994044e698c6b4bcc35add33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d544bff78a3d4d878deb3d963a786574",
            "placeholder": "​",
            "style": "IPY_MODEL_605b06d206174e44ae304996c4649503",
            "value": "Downloading: 100%"
          }
        },
        "c15a74ccc910441a8ed3b1b5d93ff90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a496a656554ca89f59f1691646cfb3",
            "max": 1115590446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_589715a05e514467a3e818e1097b6b18",
            "value": 1115590446
          }
        },
        "c7b38e71b0d44597a12f28e9e422608c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d544bff78a3d4d878deb3d963a786574": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7d67d75d1be4902bd13aa2dc0db3b00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9458f056d44517a8c534b489564f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_591077736b3e4a7b9c749d2619ae3244",
              "IPY_MODEL_c15a74ccc910441a8ed3b1b5d93ff90e",
              "IPY_MODEL_ad839379ced843c0a87278538fe02613"
            ],
            "layout": "IPY_MODEL_5936ccaca6824eb58d8b9e85cf943ba7"
          }
        },
        "ed400d78ffc94a4ba388923d3430c50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9286a9ea808c4fcfb3dcf47acf82f3cc",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b299dac695144f8a9961793726ed7eb",
            "value": 5069051
          }
        },
        "f4a496a656554ca89f59f1691646cfb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ceaca667de4993b1adfbd2f673d605": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
